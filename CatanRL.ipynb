{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOiV++9H3LLD3eJrwEPe40r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Add this to the first cell of your notebook\n","%load_ext autoreload\n","%autoreload 2  # Reload all modules (except those excluded) before executing code"],"metadata":{"id":"pnU2iekEOITt","executionInfo":{"status":"ok","timestamp":1745170228385,"user_tz":240,"elapsed":53,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyqs4AMC9RBn","executionInfo":{"status":"ok","timestamp":1745170229479,"user_tz":240,"elapsed":484,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}},"outputId":"19773f1c-0b02-414e-e136-5863d6bc26a8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install tqdm psutil plotly kaleido --quiet\n","import os\n","import sys\n","import random\n","import numpy as np\n","import time\n","import threading\n","import IPython\n","from google.colab import output\n","from datetime import datetime"],"metadata":{"id":"NdAJJ_up9TaG","executionInfo":{"status":"ok","timestamp":1745170232419,"user_tz":240,"elapsed":2292,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Ensure version compatibility with local setup\n","print(\"Installing compatible package versions...\")\n","\n","# Install specific versions to match local setup\n","!pip install torch==2.5.1 numpy==2.0.1 --quiet\n","\n","# Reload modules to ensure changes take effect\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Verify PyTorch and NumPy versions after installation\n","!python -c \"import torch; print(f'PyTorch post-install: {torch.__version__}')\"\n","!python -c \"import numpy; print(f'NumPy post-install: {numpy.__version__}')\"\n","\n","# Force CUDA setup for PyTorch\n","import torch\n","print(f\"CUDA setup: available={torch.cuda.is_available()}, device count={torch.cuda.device_count() if torch.cuda.is_available() else 0}\")\n","if torch.cuda.is_available():\n","    print(f\"Current CUDA device: {torch.cuda.current_device()}, name: {torch.cuda.get_device_name()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIKijZZvPOCr","executionInfo":{"status":"ok","timestamp":1745170238951,"user_tz":240,"elapsed":6516,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}},"outputId":"55fd832a-b20a-4f09-d911-ae78687568e8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing compatible package versions...\n","The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","PyTorch post-install: 2.5.1+cu124\n","NumPy post-install: 2.0.1\n","CUDA setup: available=True, device count=1\n","Current CUDA device: 0, name: Tesla T4\n"]}]},{"cell_type":"code","source":["# Set path to your project on Google Drive\n","DRIVE_PATH = '/content/drive/MyDrive/CatanRL'\n","\n","# Change to the project directory\n","%cd {DRIVE_PATH}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTL-hrwJ9eno","executionInfo":{"status":"ok","timestamp":1745170245899,"user_tz":240,"elapsed":690,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}},"outputId":"637d2f7a-bdc9-412e-c0c9-ce4f43d0de86"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CatanRL\n"]}]},{"cell_type":"code","source":["# Run this in a Colab cell to check device handling\n","import torch\n","\n","# Check CUDA availability\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n","    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n","    print(f\"CUDA device name: {torch.cuda.get_device_name()}\")\n","\n","# Check device of your model\n","from AlphaZero.core.network import DeepCatanNetwork\n","model = DeepCatanNetwork(992, 200, 256)\n","\n","# Try loading your checkpoint\n","checkpoint_path = '/content/drive/MyDrive/CatanRL/models/best_model.pt'\n","checkpoint = torch.load(checkpoint_path, map_location='cpu')  # Load to CPU first\n","\n","# Print device information\n","print(f\"\\nModel device before loading: {next(model.parameters()).device}\")\n","\n","# Check devices in checkpoint\n","if 'network_state_dict' in checkpoint:\n","    sample_key = list(checkpoint['network_state_dict'].keys())[0]\n","    sample_tensor = checkpoint['network_state_dict'][sample_key]\n","    print(f\"Checkpoint tensor device: {sample_tensor.device}\")\n","\n","# Try explicit device handling\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Target device: {device}\")\n","\n","# Move model to device and then load state dict\n","model = model.to(device)\n","print(f\"Model device after .to(device): {next(model.parameters()).device}\")\n","\n","# Move checkpoint tensors to the right device\n","for key in checkpoint['network_state_dict']:\n","    checkpoint['network_state_dict'][key] = checkpoint['network_state_dict'][key].to(device)\n","\n","# Now load the state dict\n","model.load_state_dict(checkpoint['network_state_dict'])\n","print(f\"Model device after loading: {next(model.parameters()).device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yePpRY3FGvHC","executionInfo":{"status":"ok","timestamp":1745170254783,"user_tz":240,"elapsed":3574,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}},"outputId":"877fd799-3f1c-4f22-da38-cc45c81a7fd4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","CUDA device count: 1\n","Current CUDA device: 0\n","CUDA device name: Tesla T4\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-2a8b476bbeea>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(checkpoint_path, map_location='cpu')  # Load to CPU first\n"]},{"output_type":"stream","name":"stdout","text":["\n","Model device before loading: cpu\n","Checkpoint tensor device: cpu\n","Target device: cuda\n","Model device after .to(device): cuda:0\n","Model device after loading: cuda:0\n"]}]},{"cell_type":"code","source":["\n","\n","def keep_colab_alive():\n","    \"\"\"\n","    This function runs in a separate thread and periodically\n","    executes JavaScript code to prevent Google Colab from disconnecting.\n","    \"\"\"\n","    while True:\n","        # Execute JavaScript to simulate user activity\n","        try:\n","            output.eval_js('new Date().toISOString()')\n","            # Make a simple fetch request to keep the connection active\n","            output.eval_js('fetch(\"https://httpbin.org/get\")')\n","            print(\"â™¥\", end=\"\", flush=True)  # Visual heartbeat\n","        except:\n","            pass\n","        time.sleep(90)  # Check every 45 seconds\n","\n","# Start the anti-disconnect thread\n","print(\"Starting anti-disconnect protection...\")\n","keep_alive_thread = threading.Thread(target=keep_colab_alive, daemon=True)\n","keep_alive_thread.start()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"f2u4zvSB_4S-","executionInfo":{"status":"ok","timestamp":1745169816029,"user_tz":240,"elapsed":25,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"}},"outputId":"5321096d-0c5d-421e-f1da-7c441485d53b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting anti-disconnect protection...\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOm4-LNE9GuY","outputId":"5d6b35b3-8723-469b-9140-269b934b7d01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Running in OVERNIGHT mode\n","\n","=== AlphaZero Catan Training ===\n","Iterations: 100\n","Self-play games per iteration: 30\n","MCTS simulations per move: 150\n","Resume from: Starting fresh\n","[2025-04-20 18:18:09] AlphaZero Catan Training started at 20250420_181809\n","[2025-04-20 18:18:09] Configuration: {'state_dim': 992, 'action_dim': 200, 'hidden_dim': 256, 'learning_rate': 0.001, 'num_iterations': 100, 'self_play_games': 30, 'eval_games': 15, 'epochs': 10, 'batch_size': 128, 'buffer_size': 100000, 'num_simulations': 150, 'c_puct': 1.5, 'mcts_batch_size': 8, 'max_moves': 200, 'model_dir': 'models', 'device': 'cuda'}\n","[2025-04-20 18:18:09] \n","=== Iteration 1/100 ===\n","[2025-04-20 18:18:09] Starting self-play...\n"]},{"output_type":"stream","name":"stderr","text":["\rSelf-play games:   0%|          | 0/30 [00:00<?, ?it/s]"]}],"source":["timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Set random seeds for reproducibility\n","def set_random_seeds(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_random_seeds()\n","\n","# Step 5: Set up training parameters\n","# You can customize these parameters\n","import argparse\n","\n","# Parse arguments from command line or use defaults\n","# This allows you to change parameters when running the notebook\n","parser = argparse.ArgumentParser(description=\"AlphaZero Catan Training\")\n","parser.add_argument(\"--iterations\", type=int, default=50, help=\"Number of training iterations\")\n","parser.add_argument(\"--resume\", type=str, default=None, help=\"Path to checkpoint to resume from\")\n","parser.add_argument(\"--games\", type=int, default=20, help=\"Number of self-play games per iteration\")\n","parser.add_argument(\"--sims\", type=int, default=100, help=\"Number of MCTS simulations per move\")\n","parser.add_argument(\"--eval-games\", type=int, default=10, help=\"Number of evaluation games\")\n","parser.add_argument(\"--quick\", action=\"store_true\", help=\"Quick training (1 iteration, 2 games)\")\n","parser.add_argument(\"--medium\", action=\"store_true\", help=\"Medium training (10 iterations, 5 games)\")\n","parser.add_argument(\"--full\", action=\"store_true\", help=\"Full training (50 iterations, 20 games)\")\n","parser.add_argument(\"--overnight\", action=\"store_true\", help=\"Overnight training (100 iterations, 30 games)\")\n","\n","# Parse the arguments directly\n","# args = parser.parse_args(['--overnight', '--resume', '/content/drive/MyDrive/CatanRL/models/best_model.pt'])  # Using existing model\n","args = parser.parse_args(['--overnight'])\n","# Configure training mode\n","if args.quick:\n","    print(\"Running in QUICK mode\")\n","    args.iterations = 1\n","    args.games = 2\n","    args.sims = 10\n","    args.eval_games = 2\n","elif args.medium:\n","    print(\"Running in MEDIUM mode\")\n","    args.iterations = 10\n","    args.games = 5\n","    args.sims = 50\n","    args.eval_games = 5\n","elif args.full:\n","    print(\"Running in FULL mode\")\n","    args.iterations = 50\n","    args.games = 20\n","    args.sims = 100\n","    args.eval_games = 10\n","elif args.overnight:\n","    print(\"Running in OVERNIGHT mode\")\n","    args.iterations = 100\n","    args.games = 30\n","    args.sims = 150\n","    args.eval_games = 15\n","\n","print(f\"\\n=== AlphaZero Catan Training ===\")\n","print(f\"Iterations: {args.iterations}\")\n","print(f\"Self-play games per iteration: {args.games}\")\n","print(f\"MCTS simulations per move: {args.sims}\")\n","print(f\"Resume from: {args.resume if args.resume else 'Starting fresh'}\")\n","\n","# Step 6: Get configuration and modify for GPU\n","from AlphaZero.utils.config import get_config\n","config = get_config()\n","\n","# Customize config with command line arguments\n","config['num_iterations'] = args.iterations\n","config['self_play_games'] = args.games\n","config['num_simulations'] = args.sims\n","config['eval_games'] = args.eval_games\n","config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Step 7: Create logs and models directories\n","!mkdir -p logs\n","!mkdir -p models\n","!mkdir -p plots\n","\n","# Step 8: Start the training\n","from AlphaZero.training.training_pipeline import TrainingPipeline\n","\n","try:\n","    # Start time tracking\n","    start_time = time.time()\n","\n","    # Create the training pipeline\n","    pipeline = TrainingPipeline(config)\n","\n","    # Train for the specified iterations\n","    pipeline.train(args.iterations, resume_from=args.resume)\n","\n","    # Calculate total training time\n","    total_time = time.time() - start_time\n","    hours = int(total_time // 3600)\n","    minutes = int((total_time % 3600) // 60)\n","    seconds = int(total_time % 60)\n","\n","    print(f\"\\nTraining completed in {hours}h {minutes}m {seconds}s\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\nTraining interrupted! Saving checkpoint...\")\n","    pipeline.save_model(pipeline.current_iteration)\n","    print(\"Checkpoint saved. You can resume with this checkpoint later.\")\n","except Exception as e:\n","    print(f\"Error during training: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","\n","# Step 9: Copy results back to Google Drive\n","!mkdir -p {DRIVE_PATH}/models_{timestamp}\n","!mkdir -p {DRIVE_PATH}/logs_{timestamp}\n","!mkdir -p {DRIVE_PATH}/plots_{timestamp}\n","\n","!cp -r models/* {DRIVE_PATH}/models_{timestamp}/\n","!cp -r logs/* {DRIVE_PATH}/logs_{timestamp}/\n","!cp -r plots/* {DRIVE_PATH}/plots_{timestamp}/\n","\n","print(f\"\\nTraining results saved to Google Drive in folders with timestamp {timestamp}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"9XnsgBD8BFWo"},"execution_count":null,"outputs":[]}]}