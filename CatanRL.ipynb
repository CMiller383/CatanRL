{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1745217112640,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"QAdl_8jWB0x7"},"outputs":[],"source":["# Add this to the first cell of your notebook\n","%load_ext autoreload\n","%autoreload 2  # Reload all modules (except those excluded) before executing code"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1745217112651,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"7qh7Y0T7_t6i"},"outputs":[],"source":["import os\n","# os.environ['CUDA_VISIBLE_DEVICES'] = ''   # comment this line if you want GPU again"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1745217112653,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"pnU2iekEOITt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1745217113319,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"pyqs4AMC9RBn","outputId":"ceae5c6f-500e-4b50-bb77-1b5564c8c02b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2089,"status":"ok","timestamp":1745217115409,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"NdAJJ_up9TaG"},"outputs":[],"source":["!pip install tqdm psutil plotly kaleido --quiet\n","import os\n","import sys\n","import random\n","import time\n","import threading\n","import IPython\n","from google.colab import output\n","from datetime import datetime"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6397,"status":"ok","timestamp":1745217121818,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"sIKijZZvPOCr","outputId":"5cc97aa7-57c1-4b3c-98a7-c3ae0b00ca0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing compatible package versions...\n","PyTorch post-install: 2.5.1+cu124\n","NumPy post-install: 2.0.1\n","CUDA setup: available=True, device count=1\n","Current CUDA device: 0, name: Tesla T4\n"]}],"source":["# Ensure version compatibility with local setup\n","print(\"Installing compatible package versions...\")\n","\n","# Install specific versions to match local setup\n","!pip install torch==2.5.1 numpy==2.0.1 --quiet\n","import numpy as np\n","\n","\n","# Verify PyTorch and NumPy versions after installation\n","!python -c \"import torch; print(f'PyTorch post-install: {torch.__version__}')\"\n","!python -c \"import numpy; print(f'NumPy post-install: {numpy.__version__}')\"\n","\n","# Force CUDA setup for PyTorch\n","import torch\n","print(f\"CUDA setup: available={torch.cuda.is_available()}, device count={torch.cuda.device_count() if torch.cuda.is_available() else 0}\")\n","if torch.cuda.is_available():\n","    print(f\"Current CUDA device: {torch.cuda.current_device()}, name: {torch.cuda.get_device_name()}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59,"status":"ok","timestamp":1745217121879,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"VTL-hrwJ9eno","outputId":"9a545d83-1de2-4692-f6ac-f51a7d0c80f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CatanRL\n"]}],"source":["# Set path to your project on Google Drive\n","DRIVE_PATH = '/content/drive/MyDrive/CatanRL'\n","\n","# Change to the project directory\n","%cd {DRIVE_PATH}\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1745217121903,"user":{"displayName":"Cole Miller","userId":"17932161436482262491"},"user_tz":240},"id":"f2u4zvSB_4S-","outputId":"fe990c3d-0415-4583-a908-e3c6e89c6616"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting keep‑alive thread …\n"]}],"source":["import time, threading\n","from google.colab import output\n","\n","# 1. Define a dummy no‑op Python callback.\n","def _noop():\n","    return \"ok\"\n","\n","# 2. Register it once – gives us a handle \"keep_alive\"\n","output.register_callback('keep_alive', _noop)\n","\n","def keep_colab_alive(interval_sec: int = 60):\n","    \"\"\"Ping the front‑end every <interval_sec> seconds.\n","\n","    Works in 2025‑04 Colab because it uses the same mechanism Colab widgets use.\n","    \"\"\"\n","    while True:\n","        try:\n","            # JS in the page calls the Python no‑op; the round‑trip is what matters\n","            output.eval_js('google.colab.kernel.invokeFunction(\"keep_alive\", [], {})')\n","            print(\"♥\", end=\"\", flush=True)\n","        except Exception:\n","            # If the socket was momentarily closed, ignore and retry\n","            pass\n","        time.sleep(interval_sec)\n","\n","print(\"Starting keep‑alive thread …\")\n","threading.Thread(target=keep_colab_alive, daemon=True).start()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOm4-LNE9GuY","outputId":"f9943bbe-f821-44ba-a9f0-eb948a1dd8c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running in OVERNIGHT mode\n","\n","=== AlphaZero Catan Training ===\n","Iterations: 100\n","Self-play games per iteration: 35\n","MCTS simulations per move: 150\n","Resume from: models/model_iter_19.pt\n","[2025-04-21 06:32:03] AlphaZero Catan Training started at 20250421_063203\n","[2025-04-21 06:32:03] Configuration: {'state_dim': 992, 'action_dim': 200, 'hidden_dim': 256, 'learning_rate': 0.001, 'num_iterations': 100, 'self_play_games': 35, 'eval_games': 20, 'epochs': 10, 'batch_size': 256, 'buffer_size': 200000, 'num_simulations': 150, 'c_puct': 1.5, 'mcts_batch_size': 32, 'max_moves': 200, 'device': 'cpu', 'model_dir': 'models'}\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/CatanRL/AlphaZero/training/training_pipeline.py:289: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(path)\n"]},{"output_type":"stream","name":"stdout","text":["[2025-04-21 06:32:05] Replay buffer loaded: 0 examples, 0.0 MB\n","[2025-04-21 06:32:05] Checkpoint loaded from models/model_iter_19.pt, resuming from iteration 19\n","[2025-04-21 06:32:05] Resuming training from iteration 19\n","[2025-04-21 06:32:05] \n","=== Iteration 20/100 ===\n","[2025-04-21 06:32:05] Starting self-play...\n"]},{"output_type":"stream","name":"stderr","text":["Self-play games:   3%|▎         | 1/35 [01:06<37:48, 66.72s/it]"]}],"source":["timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","device = torch.device('cpu')\n","\n","# Set random seeds for reproducibility\n","def set_random_seeds(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    # if torch.cuda.is_available():\n","    #     torch.cuda.manual_seed(seed)\n","    #     torch.backends.cudnn.deterministic = True\n","    #     torch.backends.cudnn.benchmark = False\n","\n","set_random_seeds()\n","\n","# Step 5: Set up training parameters\n","# You can customize these parameters\n","import argparse\n","\n","# Parse arguments from command line or use defaults\n","# This allows you to change parameters when running the notebook\n","parser = argparse.ArgumentParser(description=\"AlphaZero Catan Training\")\n","parser.add_argument(\"--iterations\", type=int, default=50, help=\"Number of training iterations\")\n","parser.add_argument(\"--resume\", type=str, default=None, help=\"Path to checkpoint to resume from\")\n","parser.add_argument(\"--games\", type=int, default=20, help=\"Number of self-play games per iteration\")\n","parser.add_argument(\"--sims\", type=int, default=100, help=\"Number of MCTS simulations per move\")\n","parser.add_argument(\"--eval-games\", type=int, default=10, help=\"Number of evaluation games\")\n","parser.add_argument(\"--quick\", action=\"store_true\", help=\"Quick training (1 iteration, 2 games)\")\n","parser.add_argument(\"--medium\", action=\"store_true\", help=\"Medium training (10 iterations, 5 games)\")\n","parser.add_argument(\"--full\", action=\"store_true\", help=\"Full training (50 iterations, 20 games)\")\n","parser.add_argument(\"--overnight\", action=\"store_true\", help=\"Overnight training (100 iterations, 30 games)\")\n","\n","# Parse the arguments directly\n","args = parser.parse_args(['--overnight', '--resume', 'models/model_iter_19.pt'])\n","#just overnight no resume\n","# args = parser.parse_args(['--medium'])\n","# Configure training mode\n","if args.quick:\n","    print(\"Running in QUICK mode\")\n","    args.iterations = 1\n","    args.games = 2\n","    args.sims = 10\n","    args.eval_games = 2\n","elif args.medium:\n","    print(\"Running in MEDIUM mode\")\n","    args.iterations = 10\n","    args.games = 5\n","    args.sims = 50\n","    args.eval_games = 5\n","elif args.full:\n","    print(\"Running in FULL mode\")\n","    args.iterations = 50\n","    args.games = 20\n","    args.sims = 100\n","    args.eval_games = 10\n","elif args.overnight:\n","    print(\"Running in OVERNIGHT mode\")\n","    args.iterations = 100\n","    args.games = 35\n","    args.sims = 150\n","    args.eval_games = 20\n","\n","print(f\"\\n=== AlphaZero Catan Training ===\")\n","print(f\"Iterations: {args.iterations}\")\n","print(f\"Self-play games per iteration: {args.games}\")\n","print(f\"MCTS simulations per move: {args.sims}\")\n","print(f\"Resume from: {args.resume if args.resume else 'Starting fresh'}\")\n","\n","# Step 6: Get configuration and modify for GPU\n","from AlphaZero.utils.config import get_config\n","config = get_config()\n","\n","# Customize config with command line arguments\n","config['num_iterations'] = args.iterations\n","config['self_play_games'] = args.games\n","config['num_simulations'] = args.sims\n","config['eval_games'] = args.eval_games\n","config['device'] = 'cpu'\n","\n","# Step 7: Create logs and models directories\n","!mkdir -p logs\n","!mkdir -p models\n","!mkdir -p plots\n","\n","# Step 8: Start the training\n","from AlphaZero.training.training_pipeline import TrainingPipeline\n","\n","try:\n","    # Start time tracking\n","    start_time = time.time()\n","\n","    # Create the training pipeline\n","    pipeline = TrainingPipeline(config)\n","\n","    # Train for the specified iterations\n","    pipeline.train(args.iterations, resume_from=args.resume)\n","\n","    # Calculate total training time\n","    total_time = time.time() - start_time\n","    hours = int(total_time // 3600)\n","    minutes = int((total_time % 3600) // 60)\n","    seconds = int(total_time % 60)\n","\n","    print(f\"\\nTraining completed in {hours}h {minutes}m {seconds}s\")\n","\n","except KeyboardInterrupt:\n","    print(\"\\nTraining interrupted! Saving checkpoint...\")\n","    pipeline.save_model(pipeline.current_iteration)\n","    print(\"Checkpoint saved. You can resume with this checkpoint later.\")\n","except Exception as e:\n","    print(f\"Error during training: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","\n","# Step 9: Copy results back to Google Drive\n","!mkdir -p {DRIVE_PATH}/models_{timestamp}\n","!mkdir -p {DRIVE_PATH}/logs_{timestamp}\n","!mkdir -p {DRIVE_PATH}/plots_{timestamp}\n","\n","!cp -r models/* {DRIVE_PATH}/models_{timestamp}/\n","!cp -r logs/* {DRIVE_PATH}/logs_{timestamp}/\n","!cp -r plots/* {DRIVE_PATH}/plots_{timestamp}/\n","\"\"\n","print(f\"\\nTraining results saved to Google Drive in folders with timestamp {timestamp}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHuFkqUoxFQS"},"outputs":[],"source":["# ===== CPU model, core / thread counts, and base turbo freq =====\n","!lscpu | egrep 'Model name|Socket|Thread|Core|MHz'\n","\n","# ===== Current clock speed of every logical core (updates once) =====\n","!grep \\\"cpu MHz\\\" /proc/cpuinfo | head\n","\n","# ===== Simple “how fast is it?” micro‑benchmark =====\n","import time, numpy as np\n","N = 6000\n","a = np.random.randn(N, N).astype(np.float32)\n","b = np.random.randn(N, N).astype(np.float32)\n","\n","t0 = time.time()\n","c = a @ b          # single BLAS call – leverages all cores & any MKL/OPENBLAS\n","elapsed = time.time() - t0\n","gflops = 2*N**3 / elapsed / 1e9\n","\n","print(f\"\\n{elapsed:.3f} s   ≈ {gflops:.1f} GFLOP/s (single large mat‑mul)\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSyRcbrx8dKw"},"outputs":[],"source":["!grep -m1 'model name' /proc/cpuinfo\n","!nproc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JTO50m079uNh"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPno3uAf1hXftKNtQVqoFF8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}